# Robot_project

### M0 Checklist

- [x] Your system can produce dead reckoning estimates (odometry)
- [x] You have collected and can display at least one rosbag where you see target objects and boxes.
- [x] You can move the robot using some input device (keyboard, mouse, gamepad, ...).
- [x] Your robot can pick up an object with the arm. You can decide what object, where it is placed, etc.
- [x] You can detect one of the objects using the RGB-D camera and mark its position in RViz.
- [x] You can visualise the data from the LiDAR in the odometry frame. This means that the LiDAR points should not move (much) when the robot moves.
    
All of you can do the following from scratch (computer and robot not started yet)

- [x] move the robot starting no windows open.
- [x] visualise the robot odometry position, the image and the point cloud from the RGB-D camera, the LiDAR and the arm camera image in RViz.
- [x] collect data into a rosbag and know how to select what to record.
- [x] play back a bag collected on the real hardware and show in RViz how it moves (according to odometry) and show the images and point clouds (RGB-D and LiDAR).

### Suggested split 
1. Robot Navigation and Control (Motion Planning) (2-3 people)
2. Mapping and Localization (SLAM or Mapping Algorithm) (2-3 people)
3. Object Detection and Classification (2-3 people)
4. Box Detection and Handling (2-3 people)
5. Robot Software Architecture, Integration, and ROS Components (all)
6. Testing, Debugging, and Performance Evaluation (all)
7. Documentation and Git Version Control (all)

